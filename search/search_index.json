{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Corpora A Dataset Studio for the Digital Humanities What is Corpora? Corpora is Digital Humanities (DH) infrastructure\u2014it's intended to be run by academic centers, libraries, or project teams, and its purpose is to greatly accelerate the development of DH projects by serving as a database, a REST API, a data collection/curation interface, and a Python-powered asynchronous task queue all wrapped into one. Corpora's name is the plural for \"corpus\" because it happily manages multiple, disparate datasets for a variety of different projects. On the same instance of Corpora, you can host one project that contains millions of bibliographic metadata records and another than contains hundreds of thousands of geolocated annotations for images. The limitations for what you can host with Corpora are determined by your hardware, not the affordances of the software. Among Corpora's affordances is a web-based interface for defining a data schema that is expected to evolve over time. This is because it is extremely rare to define a perfect schema for appropriately keeping track of project data on the first attempt. Projects happen iteratively, and so data schemas should be as effortlessly maleable as possible. Once a schema has been defined for a project, Corpora dynamically generates web forms for collaborators to enter the data. It also dynamically generates a read-only REST API for third party applications to query in order to provide, for instance, a public, front-facing website for that project. Corpora's web interface makes use of this REST API to allow scholars to search, sort, and explore the connections between their datapoints as they go about building their project. Finally, Corpora is built to cater to a wide range of users, from scholars with little technical expertise to data wranglers who want to leverage the power of Corpora's built-in iPython notebooks. Corpora also integrates a fully asynchronous job queue allowing power users to run long-running jobs (such as optical character recognition, natural language processing, TEI XML ingestion, etc.) on thousands of records at once. Defining Terms Corpus In Corpora, a \u201ccorpus\u201d is a dataset particular to an individual project. The most approachable metaphor is to think of a corpus as a collection of spreadsheets, each containing data about a different kind of thing (like books, authors, themes, etc), but ultimately all related somehow under the rubric of a project (like a project that collects metadata about literature produced in the 1890\u2019s in London). Unlike a collection of spreadsheets, however, data living in a corpus in Corpora has certain features baked in, like the ability for multiple users to log in and collect that data, the ability to sort and perform full-text searches on the data, the ability for an administrator (or corpus \u201cEditor\u201d) to add new fields for data on-the-fly, the ability to visualize the data in a network graph, and access to an API for programmers or researchers to computationally access that data, whether to perform analyses or to serve up a public-facing frontend website. Also, whereas a spreadsheet that is accessed via Excel or Google Sheets has a hard limit in terms of the amount of data you can usefully store, Corpora is built to scale up to hold millions of records while preserving all functionality. Content Type In Corpora, if a corpus is like a database, then a \u201ccontent type\u201d is like a table in that database. Or to go with the corpus-as-collection-of-spreadsheets metaphor where each spreadsheet is keeping track of a particular thing (like books, authors, themes, etc.), a content type is like one of those spreadsheets. In essence, a content type allows you to store data about a particular thing by allowing you to define it as having a collection of fields (or columns in that spreadsheet), such as, in the case of a book, fields for things like the author, title, publication date, etc. Field A field belongs to a content type, and using the spreadsheet metaphor, it\u2019s like a column in that spreadsheet in that it keeps track of a particular kind of data. So if our content type were a Book, then some common fields to describe that book would be things like author, title, publication date, etc. When creating fields for a content type, there are several types of field you can choose from, each capable of storing different kinds of data and providing different kinds of functionality. The table below lists each field type: Type Description Example Values Sortable? Supported Searches Keyword For storing relatively small (usually textual) values. If you were creating a content type for keeping track of people, you might, for instance, use a keyword field for keeping track of gender. male, female, transgender, gender neutral, non-binary, agender, pangender, genderqueer, two-spirit, third gender Yes Exact on full value Text For storing medium sized text content. Maximum size here depends on how Elasticsearch is configured, but approximately a printed page\u2019s worth of text. \u201cThis is the way the world ends / This is the way the world ends / This is the way the world ends / Not with a bang but a whimper.\u201d Yes Exact on full value, match, term, phrase, wildcard Large Text For storing a large amount of text content, such as the full text of a novel. \u201cCall me Ishmael\u2026\u201d No Match, term, phrase, wildcard HTML For storing a large amount of HTML/XML content, such as a full web page or the TEI encoded text of a novel. Searches for content with tags stripped out. <div><b>This</b> is <i>hypertext</i>!</div> No Match, term, phrase, wildcard Number Whole numbers, positive and negative. 42 Yes Exact on full value, range Decimal Floating point (decimal) numbers, positive and negative. 3.14159 Yes Exact on full value, range Boolean True of false. True Yes Exact Date A date and time. July 2nd, 1964 Yes Exact on full value, range Timespan For storing start dates and optional end dates to represent a range of time. Also features an \"uncertain\" flag that can be set, as well as a granularity value of either Day , Month , or Year . Start: January 1st, 700; End: December 31st, 1050; Uncertain: True; Granularity: Year. (An example of an uncertain publication date between the 8th and early 11th century) Yes Exact on start or end values, range File A digital file uploaded into the corpus file structure. dissertation.docx No On file path: Exact on full value, match, term, phrase, wildcard Git Repo The branch of a git repository, cloned into the file structure of the content to which it belongs. Each corpus also has a \"repos\" property which is a dictionary where the name of the repo is the key and the repo object is its value. https://github.com/bptarpley/corpora.git No None IIIF Image A IIIF image identifier for use with the IIIF image API http://iiif.some.org/iiif/2/cervantes%2F266%2F2001-Beijing-OctoberArts-01-013-f.jpg Yes Exact on full value Geo Point A longitude and latitude. -87.623713,41.879584 No Exact on full value, range Cross Reference A reference to another piece of content with a specified content type. Content of the type Book Yes Each referenced content can be searched by label, but also by any fields belonging to that content type that are marked as being \u201cin lists.\u201d All field types can be configured to hold multiple values, and you can specify whether a given field should have unique values, be full-text indexed, etc. Content In Corpora, \u201ccontent\u201d refers to a specific instance of data structured according to the various fields belonging to its content type. In the spreadsheet metaphor, content is like a row in the spreadsheet referencing a specific item in the list of similar items. Scholar A scholar is simply a user in Corpora. Scholars can view all open-access corpora, and otherwise may be granted either \u201cViewer\u201d or \u201cEditor\u201d privileges for a corpus. Viewer privileges allow scholars to see/search/explore content. Editor privileges allow them to create content, modify the content type schema, run predefined tasks, and run the Corpus Notebook. Scholars can also be granted Admin privileges, allowing them to create a new corpus, manage other scholars, and assume Editor privileges on all corpora. Task A task in Corpora is a predefined algorithm/process that can be run on a piece of content (or on your entire corpus). For example, a task named \u201cOCR with Tesseract 5\u201d might be run on content of the Document content type. Only scholars with Editor or Admin privileges can run tasks. While tasks can be launched using the Corpora web interface, tasks run asynchronously (independently) of the web interface and can take as much time as they need in order to run. The progress of a task is tracked using the web interface, and most tasks also generate a report that can be read during execution and after it has completed. Working with Corpora The following is a guide to working with the Corpora web application to create a corpus, define content types, collect and explore your data, perform searches, and run tasks, among other things. Creating a Corpus To create a corpus, you must be logged in as a scholar with Admin privileges. Assuming the domain/hostname for your instance of Corpora is mycorpora.org, you\u2019d then visit the home/root of that website to see a listing of any existing corpora, i.e. https://mycorpora.org/ When you scroll to the bottom of the page, you\u2019ll see a series of buttons\u2013click on the \u201cNew Corpus\u201d button. In the form provided, provide the following information. Name: A title for the corpus, usually an acronym or a short phrase. Description: A longer description for the purpose of distinguishing the corpus. Open Access: When this checkbox is checked, users will be able to see your content and use the various content API\u2019s to search/query your corpus without having to log into Corpora. Leaving this checkbox unchecked will mean that users will have to log in and have explicit permissions in order to see your content. Any external computers wishing to access the content API\u2019s will also need to have a scholar account with their IP addresses registered, and will also need to use an authentication token. Click the \u201cCreate\u201d button to proceed. Once the corpus has been created, you\u2019ll still be on the home screen showing the corpora available to you, but should now see your new corpus listed among them. Click on the name of your corpus to access your corpus\u2019 dashboard. The Corpus Dashboard Every corpus is assigned an alphanumeric, \u201cuniversally unique\u201d ID upon creation. It will look something like this: 645e8d37ef6052ecc78e06b7 . To visit your corpus\u2019 dashboard, you can either log into the Corpora home page and click on your corpus\u2019 name in the list of available corpora, or you can visit the URL for your corpus, which will always look like [corpora URL]/corpus/[corpus ID]/ . Assuming your corpora URL is https://mycorpora.org and your corpus ID is 645e8d37ef6052ecc78e06b7 , that URL would be: https://mycorpora.org/corpus/645e8d37ef6052ecc78e06b7/ . The corpus dashboard has several tabs. If this is an open access corpus or if you have Viewer privileges, you\u2019ll see the Content, Views, and Metadata tabs. If you\u2019re also either an Editor for this corpus or an Admin for the Corpora instance, you\u2019ll also see the \u201cAdmin\u201d tab. When on the Content tab (the default, activated tab upon visiting the dashboard page), you\u2019ll see links to all the content types listed in the gray box beneath the tab bar. These links are shortcuts to the tabular listing of all the content stored for that content type. All newly created corpora will have the following content types created already: Document, Transcription Project, and Transcription. This suite of content types come from the document plugin, which is the only plugin installed by default in Corpora. The corpus dashboard provides a large amount of functionality that is best broken out and discussed in subsequent sections of documentation. Creating Content Types Below is a video for deleting the default content types that come with a blank corpus, creating some simple content types, changing their labels, and then creating some content. For more detailed instructions, see below the video. To create a content type , you must be logged in as a scholar that is either an Editor for the corpus in question or is an Admin for the instance of Corpora, and must visit the dashboard for that corpus. Once there, click on the \u201cAdmin\u201d tab: The admin tab grants you access to much of the advanced functionality of Corpora, such as running tasks, launching the corpus iPython notebook, and deleting the corpus. Of interest for our purposes now, however, is the Content Type Manager, which can be found by scrolling down: To create a new content type, click the orange \u201cNew Content Type\u201d button on the bottom left. You\u2019ll then see the following form: In the Create Content Type form, you\u2019ll need to provide the following information. Name : This is the name of your content type that will be used to refer to it in various contexts, including a suite of URL\u2019s to access the new content creation form or to query for content via the API. For this reason, the name of a content type can\u2019t contain any special characters or spaces. If your content type is best referred to as a phrase rather than a single word (like \u201cPrinting Press\u201d), it\u2019s recommended that you type the phrase out normally (with a space) in the Name field and then hit the \u201ctab\u201d key to move down to the Plural Name field. Corpora will automatically reformat the phrase you typed (\u201cPrinting Press\u201d) to the camel-cased version of that phrase (\u201cPrintingPress\u201d). Plural Name : This will be used to refer to your content type in various user interface elements, such as the Content tab on the corpus dashboard. This field can contain spaces, so you could use something like \u201cPrinting Presses\u201d as the value for this field. Include in Navigation : This checkbox controls whether the content type will appear on the Content tab of the corpus dashboard, allowing users to view/search its content in a tabular format. If a given content type is not really intended to keep track of data relevant for scholars to see (if, for instance, it\u2019s just a content type used for computational purposes behind the scenes), uncheck this box. Index Labels for Autocompletion : Checking this box will cause the Elasticsearch index to store autocomplete information for the label of each piece of content, which you can read more about below. If you\u2019re not sure you need this, leave it unchecked as it will consume more memory, especially if you\u2019ll be storing millions of records for this content type. Once you\u2019ve filled the form out, click \u201cSave.\u201d You will then see your content type listed in the content type manager. Important note : While your choices have been saved by the user interface, they have not at this point been saved to the database. Closing your browser window or visiting another page at this point will cause you to lose your progress. Adding Fields to Your Content Type In order for a content type to be useful, you must now add fields to it. To do so, click on the name of your new content type to expand out and gain access to the \u201cfields\u201d table: Click the orange \u201cNew Field\u201d button, which will bring up the \u201cCreate New Field\u201d form: To then create a field, you\u2019ll need to provide the following information: Name : This should be the unique name of the field in a \u201csluggified\u201d format (all lowercase with no spaces or special characters other than underscores). This name is how the computer will refer to your field, how you can refer to it using the Python corpus API , and how it will appear in the JSON representation of your data in the various API\u2019s automatically created by Corpora. Label : This is the human readable label for your field, and will be used as the headers for columns in the tabular representation of your content and as the labels for field values in the create/edit/view pages automatically created by Corpora. You may use uppercase letters, spaces, and punctuation marks for field labels. Type : This is the datatype for your field, and you can read about the various types of field here . The type of field will dictate the kind of data you can store in this field, as well as the various ways in which you can search and query your data. Include in Lists : This checkbox determines whether the data stored in this field will be available in the Elasticsearch index, which provides Corpora\u2019s search capacity. If, for instance, you were only storing computational data that doesn\u2019t need to be searched, you can uncheck this box so that the data doesn\u2019t take up too much memory. Indexed : This checkbox determines whether an index for this field will be created in the MongoDB collection used to store your data. Because data also lives in Elasticsearch by default, and because Elasticsearch already provides highly efficient indexes for your fields out-of-the-box, you almost never need to check this box. If, however, you plan on storing millions of records and you plan on accessing them via MongoDB using searches that key off of this field, you may want to check this box. Note, however, that indexing every field in a content type almost never makes sense, and generally defeats the purpose of creating an index at all. Unique : Checking this box will cause MongoDB to enforce a uniqueness constraint on data stored in this field. This means that each value stored in the field will need to be unique. Attempting to save an already existing value to this field will cause the save process to fail. Multiple : Checking this box will allow you to save multiple values of the specified type to this same field. All field types support this functionality, and you\u2019re able to specify those values on the automatically generated content creation/edit form. You\u2019re also able to add multiple values to this field using the python API by treating the field as a list (or array). Once you\u2019ve made the appropriate choices to define your field, click the orange \u201cCreate\u201d button to tentatively add the field to your content type. The word tentatively is used here to highlight the fact that your content type still isn\u2019t saved/created at this point , allowing you the opportunity to continue adding fields until the content type is fully defined. When you are satisfied with how your content types(s) and fields are defined, you must save your content type schema by scrolling down below the list of content types and clicking the orange \u201cSave Changes\u201d button on the bottom right (in the same horizontal space as the \u201cNew Content Type\u201d button): Creating Content Once content types have been created you\u2019re given the opportunity to create content according to your content type schema via the corpus dashboard, specifically on the default \u201cContent\u201d tab. Once there, scroll down to the tabular representation of your specific content type and click the orange \u201cCreate\u201d button: You\u2019ll then be taken to an automatically generated web form allowing you to assign values to each of the fields defined by your content type. Once you\u2019ve entered in the desired values for your fields, click the orange \u201cSave\u201d button at the bottom left: Bulk Creating/Importing Content Often, however, entering the data manually using web forms is inefficient, especially if the data is pre-existing in other formats. There are two main ways of importing existing data. The first is to upload a CSV file containing data for a particular content type to your corpus. You can do this by going to the \u201cMetadata\u201d tab of the corpus dashboard, scrolling down to \u201cCorpus Files,\u201d and clicking the \u201cImport\u201d button. You\u2019ll need to ensure, however, that the columns of the first row in your CSV file contain field names that match the field names of your content type. You can then make use of the CSV plugin which allows you run a task to import the data from that file into your specific content type. The method has limitations, however, in that it does not support importing multi-valued fields or cross referencing between content. The second method is to make use of the Python API for Corpora which allows you to programmatically create content. Often, when going this route, it makes sense to store your source data in an external git repository. You can clone a repository into your corpus by going to the \u201cMetadata\u201d tab on the corpus dashboard, scrolling down to \u201cCorpus Repos,\u201d and clicking the orange \u201cAdd\u201d button. You\u2019ll be able to specify a name for your repo, the git URL for cloning, and the specific branch you\u2019d like to clone. Once you click \u201cSave,\u201d that repository will be immediately cloned and the files in that repo will be available in your corpus\u2019 file structure. Using the Corpus Notebook, for instance, you can then write a script in Python allowing you to pull down changes to your repo, read the updated files, and create any content accordingly. If updating content in this way is a task that will be done frequently, it may make sense to then convert that script into a Corpora task that can be launched at any time via the corpus dashboard.","title":"Getting Started"},{"location":"#corpora","text":"A Dataset Studio for the Digital Humanities","title":"Corpora"},{"location":"#what-is-corpora","text":"Corpora is Digital Humanities (DH) infrastructure\u2014it's intended to be run by academic centers, libraries, or project teams, and its purpose is to greatly accelerate the development of DH projects by serving as a database, a REST API, a data collection/curation interface, and a Python-powered asynchronous task queue all wrapped into one. Corpora's name is the plural for \"corpus\" because it happily manages multiple, disparate datasets for a variety of different projects. On the same instance of Corpora, you can host one project that contains millions of bibliographic metadata records and another than contains hundreds of thousands of geolocated annotations for images. The limitations for what you can host with Corpora are determined by your hardware, not the affordances of the software. Among Corpora's affordances is a web-based interface for defining a data schema that is expected to evolve over time. This is because it is extremely rare to define a perfect schema for appropriately keeping track of project data on the first attempt. Projects happen iteratively, and so data schemas should be as effortlessly maleable as possible. Once a schema has been defined for a project, Corpora dynamically generates web forms for collaborators to enter the data. It also dynamically generates a read-only REST API for third party applications to query in order to provide, for instance, a public, front-facing website for that project. Corpora's web interface makes use of this REST API to allow scholars to search, sort, and explore the connections between their datapoints as they go about building their project. Finally, Corpora is built to cater to a wide range of users, from scholars with little technical expertise to data wranglers who want to leverage the power of Corpora's built-in iPython notebooks. Corpora also integrates a fully asynchronous job queue allowing power users to run long-running jobs (such as optical character recognition, natural language processing, TEI XML ingestion, etc.) on thousands of records at once.","title":"What is Corpora?"},{"location":"#defining-terms","text":"","title":"Defining Terms"},{"location":"#corpus","text":"In Corpora, a \u201ccorpus\u201d is a dataset particular to an individual project. The most approachable metaphor is to think of a corpus as a collection of spreadsheets, each containing data about a different kind of thing (like books, authors, themes, etc), but ultimately all related somehow under the rubric of a project (like a project that collects metadata about literature produced in the 1890\u2019s in London). Unlike a collection of spreadsheets, however, data living in a corpus in Corpora has certain features baked in, like the ability for multiple users to log in and collect that data, the ability to sort and perform full-text searches on the data, the ability for an administrator (or corpus \u201cEditor\u201d) to add new fields for data on-the-fly, the ability to visualize the data in a network graph, and access to an API for programmers or researchers to computationally access that data, whether to perform analyses or to serve up a public-facing frontend website. Also, whereas a spreadsheet that is accessed via Excel or Google Sheets has a hard limit in terms of the amount of data you can usefully store, Corpora is built to scale up to hold millions of records while preserving all functionality.","title":"Corpus"},{"location":"#content-type","text":"In Corpora, if a corpus is like a database, then a \u201ccontent type\u201d is like a table in that database. Or to go with the corpus-as-collection-of-spreadsheets metaphor where each spreadsheet is keeping track of a particular thing (like books, authors, themes, etc.), a content type is like one of those spreadsheets. In essence, a content type allows you to store data about a particular thing by allowing you to define it as having a collection of fields (or columns in that spreadsheet), such as, in the case of a book, fields for things like the author, title, publication date, etc.","title":"Content Type"},{"location":"#field","text":"A field belongs to a content type, and using the spreadsheet metaphor, it\u2019s like a column in that spreadsheet in that it keeps track of a particular kind of data. So if our content type were a Book, then some common fields to describe that book would be things like author, title, publication date, etc. When creating fields for a content type, there are several types of field you can choose from, each capable of storing different kinds of data and providing different kinds of functionality. The table below lists each field type: Type Description Example Values Sortable? Supported Searches Keyword For storing relatively small (usually textual) values. If you were creating a content type for keeping track of people, you might, for instance, use a keyword field for keeping track of gender. male, female, transgender, gender neutral, non-binary, agender, pangender, genderqueer, two-spirit, third gender Yes Exact on full value Text For storing medium sized text content. Maximum size here depends on how Elasticsearch is configured, but approximately a printed page\u2019s worth of text. \u201cThis is the way the world ends / This is the way the world ends / This is the way the world ends / Not with a bang but a whimper.\u201d Yes Exact on full value, match, term, phrase, wildcard Large Text For storing a large amount of text content, such as the full text of a novel. \u201cCall me Ishmael\u2026\u201d No Match, term, phrase, wildcard HTML For storing a large amount of HTML/XML content, such as a full web page or the TEI encoded text of a novel. Searches for content with tags stripped out. <div><b>This</b> is <i>hypertext</i>!</div> No Match, term, phrase, wildcard Number Whole numbers, positive and negative. 42 Yes Exact on full value, range Decimal Floating point (decimal) numbers, positive and negative. 3.14159 Yes Exact on full value, range Boolean True of false. True Yes Exact Date A date and time. July 2nd, 1964 Yes Exact on full value, range Timespan For storing start dates and optional end dates to represent a range of time. Also features an \"uncertain\" flag that can be set, as well as a granularity value of either Day , Month , or Year . Start: January 1st, 700; End: December 31st, 1050; Uncertain: True; Granularity: Year. (An example of an uncertain publication date between the 8th and early 11th century) Yes Exact on start or end values, range File A digital file uploaded into the corpus file structure. dissertation.docx No On file path: Exact on full value, match, term, phrase, wildcard Git Repo The branch of a git repository, cloned into the file structure of the content to which it belongs. Each corpus also has a \"repos\" property which is a dictionary where the name of the repo is the key and the repo object is its value. https://github.com/bptarpley/corpora.git No None IIIF Image A IIIF image identifier for use with the IIIF image API http://iiif.some.org/iiif/2/cervantes%2F266%2F2001-Beijing-OctoberArts-01-013-f.jpg Yes Exact on full value Geo Point A longitude and latitude. -87.623713,41.879584 No Exact on full value, range Cross Reference A reference to another piece of content with a specified content type. Content of the type Book Yes Each referenced content can be searched by label, but also by any fields belonging to that content type that are marked as being \u201cin lists.\u201d All field types can be configured to hold multiple values, and you can specify whether a given field should have unique values, be full-text indexed, etc.","title":"Field"},{"location":"#content","text":"In Corpora, \u201ccontent\u201d refers to a specific instance of data structured according to the various fields belonging to its content type. In the spreadsheet metaphor, content is like a row in the spreadsheet referencing a specific item in the list of similar items.","title":"Content"},{"location":"#scholar","text":"A scholar is simply a user in Corpora. Scholars can view all open-access corpora, and otherwise may be granted either \u201cViewer\u201d or \u201cEditor\u201d privileges for a corpus. Viewer privileges allow scholars to see/search/explore content. Editor privileges allow them to create content, modify the content type schema, run predefined tasks, and run the Corpus Notebook. Scholars can also be granted Admin privileges, allowing them to create a new corpus, manage other scholars, and assume Editor privileges on all corpora.","title":"Scholar"},{"location":"#task","text":"A task in Corpora is a predefined algorithm/process that can be run on a piece of content (or on your entire corpus). For example, a task named \u201cOCR with Tesseract 5\u201d might be run on content of the Document content type. Only scholars with Editor or Admin privileges can run tasks. While tasks can be launched using the Corpora web interface, tasks run asynchronously (independently) of the web interface and can take as much time as they need in order to run. The progress of a task is tracked using the web interface, and most tasks also generate a report that can be read during execution and after it has completed.","title":"Task"},{"location":"#working-with-corpora","text":"The following is a guide to working with the Corpora web application to create a corpus, define content types, collect and explore your data, perform searches, and run tasks, among other things.","title":"Working with Corpora"},{"location":"#creating-a-corpus","text":"To create a corpus, you must be logged in as a scholar with Admin privileges. Assuming the domain/hostname for your instance of Corpora is mycorpora.org, you\u2019d then visit the home/root of that website to see a listing of any existing corpora, i.e. https://mycorpora.org/ When you scroll to the bottom of the page, you\u2019ll see a series of buttons\u2013click on the \u201cNew Corpus\u201d button. In the form provided, provide the following information. Name: A title for the corpus, usually an acronym or a short phrase. Description: A longer description for the purpose of distinguishing the corpus. Open Access: When this checkbox is checked, users will be able to see your content and use the various content API\u2019s to search/query your corpus without having to log into Corpora. Leaving this checkbox unchecked will mean that users will have to log in and have explicit permissions in order to see your content. Any external computers wishing to access the content API\u2019s will also need to have a scholar account with their IP addresses registered, and will also need to use an authentication token. Click the \u201cCreate\u201d button to proceed. Once the corpus has been created, you\u2019ll still be on the home screen showing the corpora available to you, but should now see your new corpus listed among them. Click on the name of your corpus to access your corpus\u2019 dashboard.","title":"Creating a Corpus"},{"location":"#the-corpus-dashboard","text":"Every corpus is assigned an alphanumeric, \u201cuniversally unique\u201d ID upon creation. It will look something like this: 645e8d37ef6052ecc78e06b7 . To visit your corpus\u2019 dashboard, you can either log into the Corpora home page and click on your corpus\u2019 name in the list of available corpora, or you can visit the URL for your corpus, which will always look like [corpora URL]/corpus/[corpus ID]/ . Assuming your corpora URL is https://mycorpora.org and your corpus ID is 645e8d37ef6052ecc78e06b7 , that URL would be: https://mycorpora.org/corpus/645e8d37ef6052ecc78e06b7/ . The corpus dashboard has several tabs. If this is an open access corpus or if you have Viewer privileges, you\u2019ll see the Content, Views, and Metadata tabs. If you\u2019re also either an Editor for this corpus or an Admin for the Corpora instance, you\u2019ll also see the \u201cAdmin\u201d tab. When on the Content tab (the default, activated tab upon visiting the dashboard page), you\u2019ll see links to all the content types listed in the gray box beneath the tab bar. These links are shortcuts to the tabular listing of all the content stored for that content type. All newly created corpora will have the following content types created already: Document, Transcription Project, and Transcription. This suite of content types come from the document plugin, which is the only plugin installed by default in Corpora. The corpus dashboard provides a large amount of functionality that is best broken out and discussed in subsequent sections of documentation.","title":"The Corpus Dashboard"},{"location":"#creating-content-types","text":"Below is a video for deleting the default content types that come with a blank corpus, creating some simple content types, changing their labels, and then creating some content. For more detailed instructions, see below the video. To create a content type , you must be logged in as a scholar that is either an Editor for the corpus in question or is an Admin for the instance of Corpora, and must visit the dashboard for that corpus. Once there, click on the \u201cAdmin\u201d tab: The admin tab grants you access to much of the advanced functionality of Corpora, such as running tasks, launching the corpus iPython notebook, and deleting the corpus. Of interest for our purposes now, however, is the Content Type Manager, which can be found by scrolling down: To create a new content type, click the orange \u201cNew Content Type\u201d button on the bottom left. You\u2019ll then see the following form: In the Create Content Type form, you\u2019ll need to provide the following information. Name : This is the name of your content type that will be used to refer to it in various contexts, including a suite of URL\u2019s to access the new content creation form or to query for content via the API. For this reason, the name of a content type can\u2019t contain any special characters or spaces. If your content type is best referred to as a phrase rather than a single word (like \u201cPrinting Press\u201d), it\u2019s recommended that you type the phrase out normally (with a space) in the Name field and then hit the \u201ctab\u201d key to move down to the Plural Name field. Corpora will automatically reformat the phrase you typed (\u201cPrinting Press\u201d) to the camel-cased version of that phrase (\u201cPrintingPress\u201d). Plural Name : This will be used to refer to your content type in various user interface elements, such as the Content tab on the corpus dashboard. This field can contain spaces, so you could use something like \u201cPrinting Presses\u201d as the value for this field. Include in Navigation : This checkbox controls whether the content type will appear on the Content tab of the corpus dashboard, allowing users to view/search its content in a tabular format. If a given content type is not really intended to keep track of data relevant for scholars to see (if, for instance, it\u2019s just a content type used for computational purposes behind the scenes), uncheck this box. Index Labels for Autocompletion : Checking this box will cause the Elasticsearch index to store autocomplete information for the label of each piece of content, which you can read more about below. If you\u2019re not sure you need this, leave it unchecked as it will consume more memory, especially if you\u2019ll be storing millions of records for this content type. Once you\u2019ve filled the form out, click \u201cSave.\u201d You will then see your content type listed in the content type manager. Important note : While your choices have been saved by the user interface, they have not at this point been saved to the database. Closing your browser window or visiting another page at this point will cause you to lose your progress.","title":"Creating Content Types"},{"location":"#adding-fields-to-your-content-type","text":"In order for a content type to be useful, you must now add fields to it. To do so, click on the name of your new content type to expand out and gain access to the \u201cfields\u201d table: Click the orange \u201cNew Field\u201d button, which will bring up the \u201cCreate New Field\u201d form: To then create a field, you\u2019ll need to provide the following information: Name : This should be the unique name of the field in a \u201csluggified\u201d format (all lowercase with no spaces or special characters other than underscores). This name is how the computer will refer to your field, how you can refer to it using the Python corpus API , and how it will appear in the JSON representation of your data in the various API\u2019s automatically created by Corpora. Label : This is the human readable label for your field, and will be used as the headers for columns in the tabular representation of your content and as the labels for field values in the create/edit/view pages automatically created by Corpora. You may use uppercase letters, spaces, and punctuation marks for field labels. Type : This is the datatype for your field, and you can read about the various types of field here . The type of field will dictate the kind of data you can store in this field, as well as the various ways in which you can search and query your data. Include in Lists : This checkbox determines whether the data stored in this field will be available in the Elasticsearch index, which provides Corpora\u2019s search capacity. If, for instance, you were only storing computational data that doesn\u2019t need to be searched, you can uncheck this box so that the data doesn\u2019t take up too much memory. Indexed : This checkbox determines whether an index for this field will be created in the MongoDB collection used to store your data. Because data also lives in Elasticsearch by default, and because Elasticsearch already provides highly efficient indexes for your fields out-of-the-box, you almost never need to check this box. If, however, you plan on storing millions of records and you plan on accessing them via MongoDB using searches that key off of this field, you may want to check this box. Note, however, that indexing every field in a content type almost never makes sense, and generally defeats the purpose of creating an index at all. Unique : Checking this box will cause MongoDB to enforce a uniqueness constraint on data stored in this field. This means that each value stored in the field will need to be unique. Attempting to save an already existing value to this field will cause the save process to fail. Multiple : Checking this box will allow you to save multiple values of the specified type to this same field. All field types support this functionality, and you\u2019re able to specify those values on the automatically generated content creation/edit form. You\u2019re also able to add multiple values to this field using the python API by treating the field as a list (or array). Once you\u2019ve made the appropriate choices to define your field, click the orange \u201cCreate\u201d button to tentatively add the field to your content type. The word tentatively is used here to highlight the fact that your content type still isn\u2019t saved/created at this point , allowing you the opportunity to continue adding fields until the content type is fully defined. When you are satisfied with how your content types(s) and fields are defined, you must save your content type schema by scrolling down below the list of content types and clicking the orange \u201cSave Changes\u201d button on the bottom right (in the same horizontal space as the \u201cNew Content Type\u201d button):","title":"Adding Fields to Your Content Type"},{"location":"#creating-content","text":"Once content types have been created you\u2019re given the opportunity to create content according to your content type schema via the corpus dashboard, specifically on the default \u201cContent\u201d tab. Once there, scroll down to the tabular representation of your specific content type and click the orange \u201cCreate\u201d button: You\u2019ll then be taken to an automatically generated web form allowing you to assign values to each of the fields defined by your content type. Once you\u2019ve entered in the desired values for your fields, click the orange \u201cSave\u201d button at the bottom left:","title":"Creating Content"},{"location":"#bulk-creatingimporting-content","text":"Often, however, entering the data manually using web forms is inefficient, especially if the data is pre-existing in other formats. There are two main ways of importing existing data. The first is to upload a CSV file containing data for a particular content type to your corpus. You can do this by going to the \u201cMetadata\u201d tab of the corpus dashboard, scrolling down to \u201cCorpus Files,\u201d and clicking the \u201cImport\u201d button. You\u2019ll need to ensure, however, that the columns of the first row in your CSV file contain field names that match the field names of your content type. You can then make use of the CSV plugin which allows you run a task to import the data from that file into your specific content type. The method has limitations, however, in that it does not support importing multi-valued fields or cross referencing between content. The second method is to make use of the Python API for Corpora which allows you to programmatically create content. Often, when going this route, it makes sense to store your source data in an external git repository. You can clone a repository into your corpus by going to the \u201cMetadata\u201d tab on the corpus dashboard, scrolling down to \u201cCorpus Repos,\u201d and clicking the orange \u201cAdd\u201d button. You\u2019ll be able to specify a name for your repo, the git URL for cloning, and the specific branch you\u2019d like to clone. Once you click \u201cSave,\u201d that repository will be immediately cloned and the files in that repo will be available in your corpus\u2019 file structure. Using the Corpus Notebook, for instance, you can then write a script in Python allowing you to pull down changes to your repo, read the updated files, and create any content accordingly. If updating content in this way is a task that will be done frequently, it may make sense to then convert that script into a Corpora task that can be launched at any time via the corpus dashboard.","title":"Bulk Creating/Importing Content"},{"location":"deploying/","text":"Deploying Corpora is built from the ground up as a \"Dockerized\" stack of services. In other words, each service lives in its own Docker container, and these containers are orchestrated to provide Corpora's functionality. The following diagram is an attempt to provide a bird's eye view of how these containers are used: Despite this complexity, Corpora was designed in order to make installing it on personal computers or servers as easy as possible thanks to the \"docker compose\" convention of orchestrating containers. Below are instructions for installing Corpora on Mac, Windows, and Linux. Prerequisites Regardless of which operating system you're using, you'll need to install Docker. The easiest way to do this on Mac or Windows is by installing Docker Desktop . For a Linux server, you'll want to install Docker and Docker Compose packages. Instructions for installing on Ubuntu, for instance, can be found here . Once Docker has been installed, you'll want to identify two different places to store files on your system. The first is where you want to clone the Corpora codebase, and the second is where you want to store the data and configuration for your instance of Corpora. These directories can exist wherever you'd like, but for the sake of convenience throughout these instructions, we'll assume you've created the directory /corpora and will be making your two directories in there. If you have Git installed on your machine, the easiest way to acquire the codebase is to clone the Corpora repository : cd /corpora git clone https://github.com/bptarpley/corpora.git codebase The commands above will create the directory /corpora/codebase and pull of the code into that directory. If you don't use git, an alternative is to download the .zip file for Corpora's code and unzip it inside the /corpora directory--for the purpose of these instructions you would then rename the unzipped folder to \"codebase.\" Once you have your codebase directory set up, you'll want to create another directory inside of /corpora called \"data.\" Make note of the path to this second directory (i.e. /corpora/data ), as you'll be needing it for creating a docker-compose.yml file in later steps. Installing and Running on Your Local Machine (Mac or Windows) Once you've installed Docker Desktop and made your two directories according to the instructions above, you'll need to go to the codebase directory and make a copy of the docker-compose.yml.example file, naming it docker-compose.yml . Note: Be sure your copy of the file lives in the same codebase directory as the original. You'll then need to edit that file using any text editor in order to replace any instance of /your/corpora/basedir with the data directory you created, i.e. /corpora/data . Having created and edited your docker-compose.yml file, you'll need to open a terminal window (Mac) or DOS prompt (Windows) and change to the codebase directory, i.e.: cd /corpora/codebase You'll then want to execute the following command to prompt Docker to pull down the necessary images and start running the Corpora stack: docker-compose up -d Note: Docker will only pull down the required images the first time you run that command, but depending on your internet connection, this may take some time. Once it has pulled the images and created each service, Corpora's startup script is set to wait a full minute before initializing--this is to give the MongoDB, Elasticsearch, and Neo4J containers enough time to spin up. If at any time you want to check the logs for the Corpora container, you can do so by executing this command in your terminal/DOS prompt: docker-compose logs -f corpora Eventually, you'll see the following log message letting you know Corpora was initialized properly: --------------------------- CORPORA INITIALIZED --------------------------- Once this happens, it may take another few seconds for the Daphne web server to actually serve the Corpora web application, but you should eventually be able to use the application by going to this URL in your local machine's browser: http://localhost . You should see Corpora's login prompt, and the default admin account's username and password are both simply corpora . To stop Corpora gracefully, you'll want to go back to the terminal/DOS prompt. If you're streaming log messages, you'll want to stop doing so by hitting CTRL+c. You'll then want to run this command: docker-compose down To get it running again, open a terminal/DOS prompt, change to the /corpora/codebase directory, and issue docker-compose up -d . Installing and Running on a Linux Server While the above instructions for running Corpora on a local machine will also work on a Linux server, there are some additional considerations when deploying it to a server that will be primarily accessed remotely. In such a scenario, you will likely have a domain name (like mycorpora.org ) you'll want to use, you'll want to use SSL to secure network traffic, and will probably want to run the Docker stack in Swarm mode rather than using Docker Compose for performance and stability. Using a Custom Domain Name In order for the Corpora web app to respond correctly to web requests at a specific domain, you'll need to add that domain to the comma-delimited list of domain names provided in the CRP_HOSTS environment variable. This can most easily be configured by editing your docker-compose.yml file. You'll want to find the following line under the \"environment\" section of the \"corpora\" service: CRP_HOSTS: localhost Append a comma directly after \"localhost\" and add your own domain name, i.e.: CRP_HOSTS: localhost,mycorpora.org Running in Swarm Mode Docker Swarm is a technology for orchestrating containers in a highly available, fault-tolerant server environment (it's what Kubernetes uses under the hood). Ideally, a fully-fledged Docker Swarm deployment would run as a cluster of servers with three master nodes and at least a couple of worker nodes, and configuring such a setup is beyond the scope of this documentation. Swarm will run, however, on a single server, and instructions for doing so are provided here for the sake of simplicity. First, make sure you've taken care of the prerequisites, made a copy of docker-compose.yml.example named docker-compose.yml and replaced all instances of /your/corpora/basedir with the path to your data directory, i.e. /corpora/data . Next, you'll want to make sure your server's Docker instance is running in Swarm mode by executing this command: docker swarm init Then, you'll want to create a private network to keep the traffic between Corpora's various services contained: docker network create -d overlay corpora-private Next, you'll want to edit the docker-compose.yml file, adding the following section to each of the services (nginx, corpora, redis, iiif, mongo, neo4j, and elastic): networks: - corpora-private At the bottom of your docker-compose.yml file, you'll then specify a separate \"networks\" section at the root level of indentation: networks: corpora-private: external: true Finally, you can actually deploy the corpora stack as a Swarm service by issuing this command inside the codebase directory: docker stack deploy corpora -c docker-compose.yml You can watch the logs for Corpora running as a Swarm service by issuing this command: docker service logs -f corpora_corpora Note: Occasionally upon starting, Nginx marks the upstream Corpora service as unavailable because it initialized much faster than the Corpora service. If this is the case, you'll see a \"Bad Gateway\" error when trying to access Corpora. To fix this, you'll want to just restart the NGINX service by executing this command: docker service update --force corpora_nginx Once everything's up and running properly, you should be able to navigate to your domain and see the Corpora login prompt. Be sure to change the password (corpora) for the default \"corpora\" user as soon as possible. To stop the Corpora services running in swarm mode, issue this command: docker stack rm corpora Using SSL Regardless of where you terminate your SSL traffic, you'll need to configure the Corpora service properly so it can be aware of the need to use the \"https\" prefix instead of \"http\" when generating internal links. To do so, you'll need to edit the docker-compose.yml file, find the line that reads CRP_USE_SSL: \"no\" and change the \"no\" value to \"yes\".","title":"Deploying"},{"location":"deploying/#deploying","text":"Corpora is built from the ground up as a \"Dockerized\" stack of services. In other words, each service lives in its own Docker container, and these containers are orchestrated to provide Corpora's functionality. The following diagram is an attempt to provide a bird's eye view of how these containers are used: Despite this complexity, Corpora was designed in order to make installing it on personal computers or servers as easy as possible thanks to the \"docker compose\" convention of orchestrating containers. Below are instructions for installing Corpora on Mac, Windows, and Linux.","title":"Deploying"},{"location":"deploying/#prerequisites","text":"Regardless of which operating system you're using, you'll need to install Docker. The easiest way to do this on Mac or Windows is by installing Docker Desktop . For a Linux server, you'll want to install Docker and Docker Compose packages. Instructions for installing on Ubuntu, for instance, can be found here . Once Docker has been installed, you'll want to identify two different places to store files on your system. The first is where you want to clone the Corpora codebase, and the second is where you want to store the data and configuration for your instance of Corpora. These directories can exist wherever you'd like, but for the sake of convenience throughout these instructions, we'll assume you've created the directory /corpora and will be making your two directories in there. If you have Git installed on your machine, the easiest way to acquire the codebase is to clone the Corpora repository : cd /corpora git clone https://github.com/bptarpley/corpora.git codebase The commands above will create the directory /corpora/codebase and pull of the code into that directory. If you don't use git, an alternative is to download the .zip file for Corpora's code and unzip it inside the /corpora directory--for the purpose of these instructions you would then rename the unzipped folder to \"codebase.\" Once you have your codebase directory set up, you'll want to create another directory inside of /corpora called \"data.\" Make note of the path to this second directory (i.e. /corpora/data ), as you'll be needing it for creating a docker-compose.yml file in later steps.","title":"Prerequisites"},{"location":"deploying/#installing-and-running-on-your-local-machine-mac-or-windows","text":"Once you've installed Docker Desktop and made your two directories according to the instructions above, you'll need to go to the codebase directory and make a copy of the docker-compose.yml.example file, naming it docker-compose.yml . Note: Be sure your copy of the file lives in the same codebase directory as the original. You'll then need to edit that file using any text editor in order to replace any instance of /your/corpora/basedir with the data directory you created, i.e. /corpora/data . Having created and edited your docker-compose.yml file, you'll need to open a terminal window (Mac) or DOS prompt (Windows) and change to the codebase directory, i.e.: cd /corpora/codebase You'll then want to execute the following command to prompt Docker to pull down the necessary images and start running the Corpora stack: docker-compose up -d Note: Docker will only pull down the required images the first time you run that command, but depending on your internet connection, this may take some time. Once it has pulled the images and created each service, Corpora's startup script is set to wait a full minute before initializing--this is to give the MongoDB, Elasticsearch, and Neo4J containers enough time to spin up. If at any time you want to check the logs for the Corpora container, you can do so by executing this command in your terminal/DOS prompt: docker-compose logs -f corpora Eventually, you'll see the following log message letting you know Corpora was initialized properly: --------------------------- CORPORA INITIALIZED --------------------------- Once this happens, it may take another few seconds for the Daphne web server to actually serve the Corpora web application, but you should eventually be able to use the application by going to this URL in your local machine's browser: http://localhost . You should see Corpora's login prompt, and the default admin account's username and password are both simply corpora . To stop Corpora gracefully, you'll want to go back to the terminal/DOS prompt. If you're streaming log messages, you'll want to stop doing so by hitting CTRL+c. You'll then want to run this command: docker-compose down To get it running again, open a terminal/DOS prompt, change to the /corpora/codebase directory, and issue docker-compose up -d .","title":"Installing and Running on Your Local Machine (Mac or Windows)"},{"location":"deploying/#installing-and-running-on-a-linux-server","text":"While the above instructions for running Corpora on a local machine will also work on a Linux server, there are some additional considerations when deploying it to a server that will be primarily accessed remotely. In such a scenario, you will likely have a domain name (like mycorpora.org ) you'll want to use, you'll want to use SSL to secure network traffic, and will probably want to run the Docker stack in Swarm mode rather than using Docker Compose for performance and stability.","title":"Installing and Running on a Linux Server"},{"location":"deploying/#using-a-custom-domain-name","text":"In order for the Corpora web app to respond correctly to web requests at a specific domain, you'll need to add that domain to the comma-delimited list of domain names provided in the CRP_HOSTS environment variable. This can most easily be configured by editing your docker-compose.yml file. You'll want to find the following line under the \"environment\" section of the \"corpora\" service: CRP_HOSTS: localhost Append a comma directly after \"localhost\" and add your own domain name, i.e.: CRP_HOSTS: localhost,mycorpora.org","title":"Using a Custom Domain Name"},{"location":"deploying/#running-in-swarm-mode","text":"Docker Swarm is a technology for orchestrating containers in a highly available, fault-tolerant server environment (it's what Kubernetes uses under the hood). Ideally, a fully-fledged Docker Swarm deployment would run as a cluster of servers with three master nodes and at least a couple of worker nodes, and configuring such a setup is beyond the scope of this documentation. Swarm will run, however, on a single server, and instructions for doing so are provided here for the sake of simplicity. First, make sure you've taken care of the prerequisites, made a copy of docker-compose.yml.example named docker-compose.yml and replaced all instances of /your/corpora/basedir with the path to your data directory, i.e. /corpora/data . Next, you'll want to make sure your server's Docker instance is running in Swarm mode by executing this command: docker swarm init Then, you'll want to create a private network to keep the traffic between Corpora's various services contained: docker network create -d overlay corpora-private Next, you'll want to edit the docker-compose.yml file, adding the following section to each of the services (nginx, corpora, redis, iiif, mongo, neo4j, and elastic): networks: - corpora-private At the bottom of your docker-compose.yml file, you'll then specify a separate \"networks\" section at the root level of indentation: networks: corpora-private: external: true Finally, you can actually deploy the corpora stack as a Swarm service by issuing this command inside the codebase directory: docker stack deploy corpora -c docker-compose.yml You can watch the logs for Corpora running as a Swarm service by issuing this command: docker service logs -f corpora_corpora Note: Occasionally upon starting, Nginx marks the upstream Corpora service as unavailable because it initialized much faster than the Corpora service. If this is the case, you'll see a \"Bad Gateway\" error when trying to access Corpora. To fix this, you'll want to just restart the NGINX service by executing this command: docker service update --force corpora_nginx Once everything's up and running properly, you should be able to navigate to your domain and see the Corpora login prompt. Be sure to change the password (corpora) for the default \"corpora\" user as soon as possible. To stop the Corpora services running in swarm mode, issue this command: docker stack rm corpora","title":"Running in Swarm Mode"},{"location":"deploying/#using-ssl","text":"Regardless of where you terminate your SSL traffic, you'll need to configure the Corpora service properly so it can be aware of the need to use the \"https\" prefix instead of \"http\" when generating internal links. To do so, you'll need to edit the docker-compose.yml file, find the line that reads CRP_USE_SSL: \"no\" and change the \"no\" value to \"yes\".","title":"Using SSL"},{"location":"developing/","text":"Developing Corpora was built with the DH developer in mind just as much as the DH scholar. It was created as a way to flexibly handle a wide variety of DH projects with minimal effort while also empowering the developer to focus on the more innovative aspects of a given project. Below are detailed the affordances of corpora tailored specifically for developers, listed in order of complexity. Content Type Templates From a developer's perspective, a Content Type in Corpora is a class whose properties and methods are largely defined by the Content Type Manager (essentially a data schema editor) available on the Admin tab of a given corpus. Content Type Templates are the convention Corpora uses to allow developers to control how instances of content get rendered , whether as a textual label, an HTML snippet, a JavaScript component, an XML document, etc. This rendering is done using the Jinja2-style Django template convention , and indeed it's recommended to refer to Django's documentation when editing or creating templates (particularly as a reference for Django's built-in template tags ). Editing Label Templates By way of example, let's consider the following Content Type used to keep track of named entities throughout a corpus of XML documents: There are four fields defined for this Content Type, which means any instance of this content will be an object with at least four properties. If we were to name an instance of this class Entity , then you'd access its four properties like this using pseudocode: Entity.xml_id Entity.entity_type Entity.name Entity.uris There are also always three more hidden properties available for any instance of Content: Entity.id # a unique, alphanumeric identifier Entity.uri # a unique URI for this content which includes its corpus ID Entity.label # a textual representation of the content The label property for any given piece of content in Corpora is generated using the template called \"Label\" which can be edited using the Content Type Manager. To edit the Label template, go to the Admin tab of your corpus, scroll to the Content Type Manager, and expand out the tray for a given Content Type. Scroll to the bottom of that tray, and locate in the footer of the table that lists the fields for your Content Type the dropdown prefixed with the label \"Edit Template.\" Click the \"Go\" button to begin editing the template used by Corpora to generate textual labels for that Content Type: In this particular case, the template for our label looks like this: {{ Entity.name }} ({{ Entity.entity_type }}) When editing a Content Type template in Corpora, the template's \"namespace\" has available to it an instance of the content named the same as the Content Type (i.e. Entity ). Django's templating system has a convention whereby you can dynamically insert the value for an object's property by surrounding it with double curly-braces. So to output the value of your Entity's name property in a template, you'd use: {{ Entity.name }} Notice this is how our template example begins. The rest of the example includes a space, open parenthesis, the output of the value for the Entity's entity_type field, and then a closing parenthesis. Given this template, if our instance of the Entity Content Type had the value \"Maria Edgeworth\" for the field name , and \"PERSON\" for the field entity_type , the textual label for that piece of content would look like this: Maria Edgeworth (PERSON) Django's templating system is powerful, as it also provides affordances for boolean logic in the form of if/else statements. Let's say we want our label template to be a little more sophisticated by having it provide default values for fields that have no value. In this case, we'll leverage Django's built-in {% if ... %} syntax : {% if Entity.name %}{{ Entity.name }}{% else %}Unknown{% endif %} ({% if Entity.entity_type %}{{ Entity.entity_type }}{% else %}UNKNOWN{% endif %}) Using this new template, if the Entity's name property has no value, the string \"Unknown\" will be output. Similarly, if entity_type has no value, \"UNKNOWN\" will be output. Note that when you make changes to a template in Corpora's Content Type Manager, you must click the orange \"Save\" button on the \"Edit Template\" modal, and must also click the orange \"Save Changes\" button in the footer of the Content Type Manager for template changes to be \"committed\" to your data schema. Also note that when the Label template is changed, Corpora automatically fires off a reindexing task for the Content Type in question, as well as for any other Content Types in your corpus that reference the Content Type in question. Depending on how many instances of these Content Types you have in your corpus, this reindexing may take some time. Creating New Templates Beyond specifying how content labels get created, Corpora's Content Type templating system allows you to create almost any kind of web-based representation of your content by allowing you to build a template and choose the appropriate MIME type for that representation. Building off our Entity example, let's say you wanted to create TEI XML representations for entities in your corpus. In the Content Type Manager for your corpus, you'd expand out the tray for your Content Type and, next to the \"Go\" button for editing an existing template, you'd click the \"New Template\" button to bring up the template editor: Give your template a URL-friendly name (no spaces or special characters), provide the content for your template, and choose an appropriate MIME Type (in this case, text/xml so we can serve up XML for the output of this template). In case the image above is too small or blurry, here's the content for this template: <person xml:id=\"{{ Entity.xml_id }}\"> <persName>{{ Entity.name }}</persName> </person> Click the \"Save\" button on the template editing modal, and then click \"Save Changes\" at the bottom of the Content Type Manager. Once this happens, your new template is available to be rendered. Viewing Rendered Templates To view the output of a template for an instance of content, you'll need to construct a URL that follows this convention: [Your Corpora Instance]/corpus/[Corpus ID]/[Content Type]/[Content ID]/?render_template=[Template Name] In this example, let's assume your Corpora instance is hosted at https://mycorpora.org , your Corpus ID is 62f554a9837071d8c4910dg , the Content Type is Entity , the ID for your instance of Entity is 6691462b32399974cfc2cb1a , and the template you want to render is our new TEI-XML-Person template. Given these assumptions, the URL would look like: https://mycorpora.org/corpus/62f554a9837071d8c4910dg/Entity/6691462b32399974cfc2cb1a/?render_template=TEI-XML-Person Your browser should then display the rendered output for your content as an XML document (screenshot from Google Chrome): Corpus API for Python The corpus API for Python does most of the heavy lifting behind the scenes in terms of the C.R.U.D. (creating, reading, updating, and deleting) operations on corpus data. Understanding how to use it is crucial to using the corpus iPython notebook and writing plugins for Corpora. At its heart, the API leverages MongoEngine --an ORM for MongoDB designed to behave similarly to the SQL-oriented ORM baked into Django . In fact, each corpus or content object is a MongoEngine Document under the hood, and when you query for content using the corpus API, you're actually working with MongoEngine QuerySets . As such, the majority of the documentation for the corpus API is covered by MongoEngine's documentation, so much of the documentation here will be in the form of examples. Creating a Corpus from corpus import Corpus my_corpus = Corpus() my_corpus.name = \"MTC\" my_corpus.description = \"My Test Corpus\" my_corpus.save() Upon running the above script, the my_corpus variable will be an instance of mongoengine.Document . After saving it, the id property of my_corpus will be a BSON ObjectId, which is how MongoDB uniquely identifies each document. The alphanumeric string representation of the ObjectId can be acquired like so: my_corpus_id_as_a_string = str(my_corpus.id) Retrieving a Corpus from corpus import get_corpus my_corpus = get_corpus('6661e28c4399e45f0bfd2121') The get_corpus function will accept as its first parameter either a string or a BSON ObjectId and will return an instance of the Corpus object, which is ultimately a MongoEngine Document with the following properties: Property Data Type Purpose name string To provide a brief project label, typically an acronym. description string To provide a full project descriptor, typically the spelled out version of the project's name. uri string This property is generated when the corpus is first saved, and it provides a unique URI for the corpus as it exists on the instance of Corpora hosting it. path string Generated upon first save. It contains the file path to the corpus' files within the Corpora Docker container, should it have any. kvp dictionary KVP stands for \"key/value pairs,\" and it's intended to house arbitrary metadata (rarely used). files dictionary The keys for the dictionary are unique hashes based on the file's path. These are long alphanumeric strings. The values are File objects . repos dictionary The keys are the name given to the repo, and the values are Repo objects . open_access boolean A flag for determining whether a corpus is open access, making its read-only API publicly available. content_types dictionary The keys are the name of a given Content Type, and the values are a dictionary specifying the metadata for a given Content Type and its fields. provenance list A list of completed jobs for this corpus. A corpus object also has several methods which will be covered in subsequent sections. Creating Content With a corpus object in hand, you can create content using the corpus' get_content method. This example assumes you have a Content Type called \"Document\" in your corpus: new_document = my_corpus.get_content('Document') new_document.title = \"On Beauty\" new_document.author = \"Zadie Smith\" new_document.save() Calling your corpus' get_content method by only passing in the Content Type name will return an instance of a MongoEngine document with that Content Type's fields as properties to be set. Once you've set those field values, you call the save method to save the content and assign it a unique ID. Note: When saving content, the data is first saved to MongoDB. Post-save events then fire which also index the content in Elasticsearch and link the data in Neo4J. As such, saving content can be relatively time consuming, especially when saving in bulk. In cases where bulk saving needs to occur, you can turn off indexing and/or linking like so: # Saves to MongoDB and Neo4J, but not Elasticsearch: new_document.save(do_indexing=False) # Saves to MongoDB and Elasticsearch, but not Neo4J: new_document.save(do_linking=False) # Saves only to MongoDB: new_document.save(do_indexing=False, do_linking=False) If you later want to fire off a job to index and link all of your content, you can do so like this: my_corpus.queue_local_job(task_name=\"Adjust Content\", parameters={ 'content_type': 'Document', 'reindex': True, 'relabel': True }) Retrieving Content Your corpus' get_content method is also useful for retrieving content when you know either the ID or exact field values for your content. When using get_content to retrieve content, you're ultimately querying MongoDB: # Query for a single piece of content with the ID known: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') print(content.title) \"On Beauty\" # Query for a single piece of content by field value: content = my_corpus.get_content('Document', {'title': \"On Beauty\"}, single_result=True) # Query for multiple pieces of content by field value: contents = my_corpus.get_content('Document', {'author': \"Zadie Smith\"}) for content in contents: print(content.title) \"White Teeth\" \"On Beauty\" # Query for all content with this Content Type: contents = my_corpus.get_content('Document', all=True) When retrieving a single piece of content, you receive a MongoEngine Document. When retrieving multiple pieces of content, you receive a MongoEngine QuerySet. QuerySets are generators (can be iterated over using a for-loop), but also have their own methods, like count : contents = my_corpus.get_content('Document', all=True) contents.count() 42 Editing Content Once you've retrieved a single piece of content using get_content , you can directly edit its field values and then call save to edit it: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') content.published_year = 2005 content.save() Deleting Content Deleting content is as simple as calling the MongoEngine Document's delete method: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') content.delete() Note: because content can be cross-referenced in arbitrary ways, deleting content saves a stub in the database that tells Corpora to sweep for instances of other content that references the deleted content so as to remove those references. When deleting large quantities of content, this can cause a backlog of deletion stubs. If you know you'll be deleting a large amount of content, and you also feel certain there's no need to track these deletions in order to hunt for stale content references, you can skip the creation of a deletion stub like so: content.delete(track_deletions=False) Working with Cross-Referenced Content Much of the value of Corpora's Neo4J database is in its ability to keep track of the way your content is related, allowing the interface to visualize these connections. Content becomes \"related\" to other content via fields of type cross-reference . By way of example, let's assume you're working with a corpus that has two Content Types: Entity and Letter . And let's say that the Letter has a field called recipient of type cross-reference that specifically references the type Entity . In this way, a Letter can reference a specific Entity via its recipient field. Let's create an Entity and a Letter, and \"relate\" them appropriately: entity = my_corpus.get_content('Entity') entity.name = \"Elizabeth Barrett Browning\" entity.save() letter = my_corpus.get_content('Letter') letter.contents = \"Real warm spring, dear Miss Barrett, and the birds know it, and in Spring I shall see you, really see you...\" letter.recipient = entity.id letter.save() Note how when specifying the value of the recipient field for our instance of Letter , we used the id property of Entity . If the \"multiple\" box is checked when creating a field of type cross-reference , the field is actually a list, and so content ID's must be appended to the list: letter.recipients.append(entity.id) letter.save() You may query for content using cross-referenced fields, and the easiest way to do this is with the ObjectId (or its string representation) of the cross-referenced content. For example: letters_to_elizabeth = my_corpus.get_content('Letter', {'recipient': '66a166e56cf2fb23103b58b2'}) You may also access the values of nested fields for cross-referenced content like so: first_letter = letters_to_elizabeth[0] print(first_letter.recipient.name) \"Elizabeth Barrett Browning\" Working with Files In Corpora, files belonging to a corpus or to a piece of content are ultimately registered as File objects, which themselves are a MongoEngine Embedded Document with the following properties: Property Data Type Purpose path string To keep track of the file path as it exists inside the Corpora container. primary_witness boolean To flag whether the file should be the primary \"witness\" or digital surrogate for the content in question. Currently only used in the context of the Document plugin. basename string The filename of the file (without the path), i.e. \"data.csv\" extension string The extension of the file, i.e. \"csv\" byte_size integer The size of the file in bytes description string Human-readable description of the file provenance_type string To track what kind of thing originated this file, i.e. \"Tesseract OCR Job\" provenance_id string A unique identifier for the thing that originated this file, i.e. \"4213\" height integer The height in pixels of the file (if it's an image) width integer The width in pixels of the file (if it's an image) iiif_info dict A dictionary representing the kind of metadata you get when querying for /info.json on a IIIF server While those properties can be helpful, the only required property when creating a File object to represent a file is the path . The path of a file is always relative to the Corpora container. When the file is directly associated with a corpus, it lives in the /files directory, itself living in the directory specified by the corpus' path property. A directory is created in the Corpora container any time a corpus is created, and its path always looks like /corpora/[corpus ID] . As such, files directly associated with a corpus should live inside the /corpus/[corpus ID]/files directory. The best way to associate a file with a corpus is via the corpus' homepage by going to the \"Metadata\" tab and clicking the orange \"Import\" button next to \"Corpus Files.\" When you import files like this, it saves them in a files directory living inside of the directory specified in the path property of the corpus. Imported files are also registered in the files dictionary of your corpus object. The keys for the files dictionary of a corpus are hashes based on the file's path--this is to provide a URL-friendly way of accessing them. This makes retrieving them programmatically in Python a little unintuitive, however. Let's say you upload a file called entities.csv to your corpus. To access that file with Python, you'll need to get its path like so: entities_csv_path = None for file_key in my_corpus.files.keys(): if 'entities.csv' in my_corpus.files[file_key].path: entities_csv_path = my_corpus.files[file_key].path Content Types can also specify \"File\" as a type of field, and in those cases, you may directly access the path property of the file (no intervening dictionary with file key hashes): photo = my_corpus.get_content('Photo', '66a166e56cf2fb23103b6h7') photo.original_file.path When files belong to an instance of content (rather than directly associated with a corpus), that piece of content gets its own path property and a directory is created for it (directories are normally not created for content--only when they have files associated with them). Content paths always look like this: /corpora/[corpus ID]/[Content Type]/[breakout directory]/[content ID] Given that millions of instances of a Content Type could exist for a corpus, Corpora implements a \"breakout directory\" to prevent any one directory from containing millions of subdirectories! Much like with a corpus, files associated with content live inside the /files subdirectory of a content instance's path, i.e.: /corpora/[corpus ID]/[Content Type]/[breakout directory]/[content ID]/files When programmatically associating a file to a corpus or piece of content, it's important for that file to live in the correct place, as this allows all the files belonging to a corpus to be exported and restored appropriately. To programmatically associate a file directly with a corpus, first upload it to the corpus' appropriate /files subdirectory and make note of its full path. Then: from corpus import get_corpus, File # store the path to the file in a variable my_file_path = '/corpora/6661e28c4399e45f0bfd2121/files/data.csv' # retrieve your corpus my_corpus = get_corpus('6661e28c4399e45f0bfd2121') # create an instance of the File object by using its \"process\" method # which takes at minimum the path to the file my_file = File.process(my_file_path) # generate a file key for storing the file in the corpus my_file_key = File.generate_key(my_file_path) my_corpus.files[my_file_key] = my_file my_corpus.save() Note the use of the process class method of File. That method takes a file path, checks to see if the file exists, gathers some minimal metadata about the file (like file size), and returns a File object. Because files directly associated with a corpus are stored using a file key, we generate one with the generate_key method of File.","title":"Developing"},{"location":"developing/#developing","text":"Corpora was built with the DH developer in mind just as much as the DH scholar. It was created as a way to flexibly handle a wide variety of DH projects with minimal effort while also empowering the developer to focus on the more innovative aspects of a given project. Below are detailed the affordances of corpora tailored specifically for developers, listed in order of complexity.","title":"Developing"},{"location":"developing/#content-type-templates","text":"From a developer's perspective, a Content Type in Corpora is a class whose properties and methods are largely defined by the Content Type Manager (essentially a data schema editor) available on the Admin tab of a given corpus. Content Type Templates are the convention Corpora uses to allow developers to control how instances of content get rendered , whether as a textual label, an HTML snippet, a JavaScript component, an XML document, etc. This rendering is done using the Jinja2-style Django template convention , and indeed it's recommended to refer to Django's documentation when editing or creating templates (particularly as a reference for Django's built-in template tags ).","title":"Content Type Templates"},{"location":"developing/#editing-label-templates","text":"By way of example, let's consider the following Content Type used to keep track of named entities throughout a corpus of XML documents: There are four fields defined for this Content Type, which means any instance of this content will be an object with at least four properties. If we were to name an instance of this class Entity , then you'd access its four properties like this using pseudocode: Entity.xml_id Entity.entity_type Entity.name Entity.uris There are also always three more hidden properties available for any instance of Content: Entity.id # a unique, alphanumeric identifier Entity.uri # a unique URI for this content which includes its corpus ID Entity.label # a textual representation of the content The label property for any given piece of content in Corpora is generated using the template called \"Label\" which can be edited using the Content Type Manager. To edit the Label template, go to the Admin tab of your corpus, scroll to the Content Type Manager, and expand out the tray for a given Content Type. Scroll to the bottom of that tray, and locate in the footer of the table that lists the fields for your Content Type the dropdown prefixed with the label \"Edit Template.\" Click the \"Go\" button to begin editing the template used by Corpora to generate textual labels for that Content Type: In this particular case, the template for our label looks like this: {{ Entity.name }} ({{ Entity.entity_type }}) When editing a Content Type template in Corpora, the template's \"namespace\" has available to it an instance of the content named the same as the Content Type (i.e. Entity ). Django's templating system has a convention whereby you can dynamically insert the value for an object's property by surrounding it with double curly-braces. So to output the value of your Entity's name property in a template, you'd use: {{ Entity.name }} Notice this is how our template example begins. The rest of the example includes a space, open parenthesis, the output of the value for the Entity's entity_type field, and then a closing parenthesis. Given this template, if our instance of the Entity Content Type had the value \"Maria Edgeworth\" for the field name , and \"PERSON\" for the field entity_type , the textual label for that piece of content would look like this: Maria Edgeworth (PERSON) Django's templating system is powerful, as it also provides affordances for boolean logic in the form of if/else statements. Let's say we want our label template to be a little more sophisticated by having it provide default values for fields that have no value. In this case, we'll leverage Django's built-in {% if ... %} syntax : {% if Entity.name %}{{ Entity.name }}{% else %}Unknown{% endif %} ({% if Entity.entity_type %}{{ Entity.entity_type }}{% else %}UNKNOWN{% endif %}) Using this new template, if the Entity's name property has no value, the string \"Unknown\" will be output. Similarly, if entity_type has no value, \"UNKNOWN\" will be output. Note that when you make changes to a template in Corpora's Content Type Manager, you must click the orange \"Save\" button on the \"Edit Template\" modal, and must also click the orange \"Save Changes\" button in the footer of the Content Type Manager for template changes to be \"committed\" to your data schema. Also note that when the Label template is changed, Corpora automatically fires off a reindexing task for the Content Type in question, as well as for any other Content Types in your corpus that reference the Content Type in question. Depending on how many instances of these Content Types you have in your corpus, this reindexing may take some time.","title":"Editing Label Templates"},{"location":"developing/#creating-new-templates","text":"Beyond specifying how content labels get created, Corpora's Content Type templating system allows you to create almost any kind of web-based representation of your content by allowing you to build a template and choose the appropriate MIME type for that representation. Building off our Entity example, let's say you wanted to create TEI XML representations for entities in your corpus. In the Content Type Manager for your corpus, you'd expand out the tray for your Content Type and, next to the \"Go\" button for editing an existing template, you'd click the \"New Template\" button to bring up the template editor: Give your template a URL-friendly name (no spaces or special characters), provide the content for your template, and choose an appropriate MIME Type (in this case, text/xml so we can serve up XML for the output of this template). In case the image above is too small or blurry, here's the content for this template: <person xml:id=\"{{ Entity.xml_id }}\"> <persName>{{ Entity.name }}</persName> </person> Click the \"Save\" button on the template editing modal, and then click \"Save Changes\" at the bottom of the Content Type Manager. Once this happens, your new template is available to be rendered.","title":"Creating New Templates"},{"location":"developing/#viewing-rendered-templates","text":"To view the output of a template for an instance of content, you'll need to construct a URL that follows this convention: [Your Corpora Instance]/corpus/[Corpus ID]/[Content Type]/[Content ID]/?render_template=[Template Name] In this example, let's assume your Corpora instance is hosted at https://mycorpora.org , your Corpus ID is 62f554a9837071d8c4910dg , the Content Type is Entity , the ID for your instance of Entity is 6691462b32399974cfc2cb1a , and the template you want to render is our new TEI-XML-Person template. Given these assumptions, the URL would look like: https://mycorpora.org/corpus/62f554a9837071d8c4910dg/Entity/6691462b32399974cfc2cb1a/?render_template=TEI-XML-Person Your browser should then display the rendered output for your content as an XML document (screenshot from Google Chrome):","title":"Viewing Rendered Templates"},{"location":"developing/#corpus-api-for-python","text":"The corpus API for Python does most of the heavy lifting behind the scenes in terms of the C.R.U.D. (creating, reading, updating, and deleting) operations on corpus data. Understanding how to use it is crucial to using the corpus iPython notebook and writing plugins for Corpora. At its heart, the API leverages MongoEngine --an ORM for MongoDB designed to behave similarly to the SQL-oriented ORM baked into Django . In fact, each corpus or content object is a MongoEngine Document under the hood, and when you query for content using the corpus API, you're actually working with MongoEngine QuerySets . As such, the majority of the documentation for the corpus API is covered by MongoEngine's documentation, so much of the documentation here will be in the form of examples.","title":"Corpus API for Python"},{"location":"developing/#creating-a-corpus","text":"from corpus import Corpus my_corpus = Corpus() my_corpus.name = \"MTC\" my_corpus.description = \"My Test Corpus\" my_corpus.save() Upon running the above script, the my_corpus variable will be an instance of mongoengine.Document . After saving it, the id property of my_corpus will be a BSON ObjectId, which is how MongoDB uniquely identifies each document. The alphanumeric string representation of the ObjectId can be acquired like so: my_corpus_id_as_a_string = str(my_corpus.id)","title":"Creating a Corpus"},{"location":"developing/#retrieving-a-corpus","text":"from corpus import get_corpus my_corpus = get_corpus('6661e28c4399e45f0bfd2121') The get_corpus function will accept as its first parameter either a string or a BSON ObjectId and will return an instance of the Corpus object, which is ultimately a MongoEngine Document with the following properties: Property Data Type Purpose name string To provide a brief project label, typically an acronym. description string To provide a full project descriptor, typically the spelled out version of the project's name. uri string This property is generated when the corpus is first saved, and it provides a unique URI for the corpus as it exists on the instance of Corpora hosting it. path string Generated upon first save. It contains the file path to the corpus' files within the Corpora Docker container, should it have any. kvp dictionary KVP stands for \"key/value pairs,\" and it's intended to house arbitrary metadata (rarely used). files dictionary The keys for the dictionary are unique hashes based on the file's path. These are long alphanumeric strings. The values are File objects . repos dictionary The keys are the name given to the repo, and the values are Repo objects . open_access boolean A flag for determining whether a corpus is open access, making its read-only API publicly available. content_types dictionary The keys are the name of a given Content Type, and the values are a dictionary specifying the metadata for a given Content Type and its fields. provenance list A list of completed jobs for this corpus. A corpus object also has several methods which will be covered in subsequent sections.","title":"Retrieving a Corpus"},{"location":"developing/#creating-content","text":"With a corpus object in hand, you can create content using the corpus' get_content method. This example assumes you have a Content Type called \"Document\" in your corpus: new_document = my_corpus.get_content('Document') new_document.title = \"On Beauty\" new_document.author = \"Zadie Smith\" new_document.save() Calling your corpus' get_content method by only passing in the Content Type name will return an instance of a MongoEngine document with that Content Type's fields as properties to be set. Once you've set those field values, you call the save method to save the content and assign it a unique ID. Note: When saving content, the data is first saved to MongoDB. Post-save events then fire which also index the content in Elasticsearch and link the data in Neo4J. As such, saving content can be relatively time consuming, especially when saving in bulk. In cases where bulk saving needs to occur, you can turn off indexing and/or linking like so: # Saves to MongoDB and Neo4J, but not Elasticsearch: new_document.save(do_indexing=False) # Saves to MongoDB and Elasticsearch, but not Neo4J: new_document.save(do_linking=False) # Saves only to MongoDB: new_document.save(do_indexing=False, do_linking=False) If you later want to fire off a job to index and link all of your content, you can do so like this: my_corpus.queue_local_job(task_name=\"Adjust Content\", parameters={ 'content_type': 'Document', 'reindex': True, 'relabel': True })","title":"Creating Content"},{"location":"developing/#retrieving-content","text":"Your corpus' get_content method is also useful for retrieving content when you know either the ID or exact field values for your content. When using get_content to retrieve content, you're ultimately querying MongoDB: # Query for a single piece of content with the ID known: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') print(content.title) \"On Beauty\" # Query for a single piece of content by field value: content = my_corpus.get_content('Document', {'title': \"On Beauty\"}, single_result=True) # Query for multiple pieces of content by field value: contents = my_corpus.get_content('Document', {'author': \"Zadie Smith\"}) for content in contents: print(content.title) \"White Teeth\" \"On Beauty\" # Query for all content with this Content Type: contents = my_corpus.get_content('Document', all=True) When retrieving a single piece of content, you receive a MongoEngine Document. When retrieving multiple pieces of content, you receive a MongoEngine QuerySet. QuerySets are generators (can be iterated over using a for-loop), but also have their own methods, like count : contents = my_corpus.get_content('Document', all=True) contents.count() 42","title":"Retrieving Content"},{"location":"developing/#editing-content","text":"Once you've retrieved a single piece of content using get_content , you can directly edit its field values and then call save to edit it: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') content.published_year = 2005 content.save()","title":"Editing Content"},{"location":"developing/#deleting-content","text":"Deleting content is as simple as calling the MongoEngine Document's delete method: content = my_corpus.get_content('Document', '5f623f2a52023c009d73108e') content.delete() Note: because content can be cross-referenced in arbitrary ways, deleting content saves a stub in the database that tells Corpora to sweep for instances of other content that references the deleted content so as to remove those references. When deleting large quantities of content, this can cause a backlog of deletion stubs. If you know you'll be deleting a large amount of content, and you also feel certain there's no need to track these deletions in order to hunt for stale content references, you can skip the creation of a deletion stub like so: content.delete(track_deletions=False)","title":"Deleting Content"},{"location":"developing/#working-with-cross-referenced-content","text":"Much of the value of Corpora's Neo4J database is in its ability to keep track of the way your content is related, allowing the interface to visualize these connections. Content becomes \"related\" to other content via fields of type cross-reference . By way of example, let's assume you're working with a corpus that has two Content Types: Entity and Letter . And let's say that the Letter has a field called recipient of type cross-reference that specifically references the type Entity . In this way, a Letter can reference a specific Entity via its recipient field. Let's create an Entity and a Letter, and \"relate\" them appropriately: entity = my_corpus.get_content('Entity') entity.name = \"Elizabeth Barrett Browning\" entity.save() letter = my_corpus.get_content('Letter') letter.contents = \"Real warm spring, dear Miss Barrett, and the birds know it, and in Spring I shall see you, really see you...\" letter.recipient = entity.id letter.save() Note how when specifying the value of the recipient field for our instance of Letter , we used the id property of Entity . If the \"multiple\" box is checked when creating a field of type cross-reference , the field is actually a list, and so content ID's must be appended to the list: letter.recipients.append(entity.id) letter.save() You may query for content using cross-referenced fields, and the easiest way to do this is with the ObjectId (or its string representation) of the cross-referenced content. For example: letters_to_elizabeth = my_corpus.get_content('Letter', {'recipient': '66a166e56cf2fb23103b58b2'}) You may also access the values of nested fields for cross-referenced content like so: first_letter = letters_to_elizabeth[0] print(first_letter.recipient.name) \"Elizabeth Barrett Browning\"","title":"Working with Cross-Referenced Content"},{"location":"developing/#working-with-files","text":"In Corpora, files belonging to a corpus or to a piece of content are ultimately registered as File objects, which themselves are a MongoEngine Embedded Document with the following properties: Property Data Type Purpose path string To keep track of the file path as it exists inside the Corpora container. primary_witness boolean To flag whether the file should be the primary \"witness\" or digital surrogate for the content in question. Currently only used in the context of the Document plugin. basename string The filename of the file (without the path), i.e. \"data.csv\" extension string The extension of the file, i.e. \"csv\" byte_size integer The size of the file in bytes description string Human-readable description of the file provenance_type string To track what kind of thing originated this file, i.e. \"Tesseract OCR Job\" provenance_id string A unique identifier for the thing that originated this file, i.e. \"4213\" height integer The height in pixels of the file (if it's an image) width integer The width in pixels of the file (if it's an image) iiif_info dict A dictionary representing the kind of metadata you get when querying for /info.json on a IIIF server While those properties can be helpful, the only required property when creating a File object to represent a file is the path . The path of a file is always relative to the Corpora container. When the file is directly associated with a corpus, it lives in the /files directory, itself living in the directory specified by the corpus' path property. A directory is created in the Corpora container any time a corpus is created, and its path always looks like /corpora/[corpus ID] . As such, files directly associated with a corpus should live inside the /corpus/[corpus ID]/files directory. The best way to associate a file with a corpus is via the corpus' homepage by going to the \"Metadata\" tab and clicking the orange \"Import\" button next to \"Corpus Files.\" When you import files like this, it saves them in a files directory living inside of the directory specified in the path property of the corpus. Imported files are also registered in the files dictionary of your corpus object. The keys for the files dictionary of a corpus are hashes based on the file's path--this is to provide a URL-friendly way of accessing them. This makes retrieving them programmatically in Python a little unintuitive, however. Let's say you upload a file called entities.csv to your corpus. To access that file with Python, you'll need to get its path like so: entities_csv_path = None for file_key in my_corpus.files.keys(): if 'entities.csv' in my_corpus.files[file_key].path: entities_csv_path = my_corpus.files[file_key].path Content Types can also specify \"File\" as a type of field, and in those cases, you may directly access the path property of the file (no intervening dictionary with file key hashes): photo = my_corpus.get_content('Photo', '66a166e56cf2fb23103b6h7') photo.original_file.path When files belong to an instance of content (rather than directly associated with a corpus), that piece of content gets its own path property and a directory is created for it (directories are normally not created for content--only when they have files associated with them). Content paths always look like this: /corpora/[corpus ID]/[Content Type]/[breakout directory]/[content ID] Given that millions of instances of a Content Type could exist for a corpus, Corpora implements a \"breakout directory\" to prevent any one directory from containing millions of subdirectories! Much like with a corpus, files associated with content live inside the /files subdirectory of a content instance's path, i.e.: /corpora/[corpus ID]/[Content Type]/[breakout directory]/[content ID]/files When programmatically associating a file to a corpus or piece of content, it's important for that file to live in the correct place, as this allows all the files belonging to a corpus to be exported and restored appropriately. To programmatically associate a file directly with a corpus, first upload it to the corpus' appropriate /files subdirectory and make note of its full path. Then: from corpus import get_corpus, File # store the path to the file in a variable my_file_path = '/corpora/6661e28c4399e45f0bfd2121/files/data.csv' # retrieve your corpus my_corpus = get_corpus('6661e28c4399e45f0bfd2121') # create an instance of the File object by using its \"process\" method # which takes at minimum the path to the file my_file = File.process(my_file_path) # generate a file key for storing the file in the corpus my_file_key = File.generate_key(my_file_path) my_corpus.files[my_file_key] = my_file my_corpus.save() Note the use of the process class method of File. That method takes a file path, checks to see if the file exists, gathers some minimal metadata about the file (like file size), and returns a File object. Because files directly associated with a corpus are stored using a file key, we generate one with the generate_key method of File.","title":"Working with Files"},{"location":"managing/","text":"Managing There are a few tasks, such as managing users, backing up and restoring corpus data, and installing plugins that Corpora admins may need to perform. Managing Users To manage the users (or Scholars) on your instance of Corpora, click the blue \"Manage Scholars\" button in the footer of the table listing corpora on the homepage of the web application. Once on the \"Scholars\" page, you should see a table listing all the users in your instance of Corpora. You may click on the column names to sort, you can use the search box, or page through this list in order to find your user. Once you've found them, click on their username which should also be an orange link. This will bring up the \"Manage Scholar\" modal. Granting/Revoking Admin Privileges Admins in Corpora are able to create a new corpus, view and edit all data for existing corpora, run all corpus notebooks, and run all tasks. You can make a user an admin for your instance of Corpora by clicking the orange \"Grant Admin Privileges\" button. Once a user is an admin, that same button will read \"Revoke Admin Privileges.\" Granting/Revoking Corpus Permissions In order for a user to edit content, run a corpus notebook, or run certain tasks, they must either be an Admin for the instance of Corpora or be granted \"Editor\" privileges on a specific corpus. To do the latter, expand the \"Corpus permissions\" tray. In the \"New Permission\" form, provide the name of the corpus, choose \"Editor\" from the dropdown menu, and click \"Set Permission.\" To revoke that privilege, find it under \"Existing Permissions\" and choose \"None\" from the dropdown. Granting/Revoking Job Permissions While admins can run all jobs, users with Editor permissions on a corpus must be explicitly granted permission to run specific jobs. To do so, expand out the user's \"Job permissions\" tray. You can either check the box next to the specific task they need to be able to run, or check the \"Local (HUEY)\" box, which grants them privileges to run every local task. Once you've checked the appropriate box(es), click the orange \"Set Permissions\" button. Job permissions can be revoked by unchecking boxes and clicking \"Set Permissions\" again. Changing Passwords When logged in, individual users can change their passwords by clicking on the orange \"My Account\" button on the top right of a page in Corpora. Should they need their passwords reset, however, you may do so by pulling up their \"Manage Scholar\" modal and expanding the \"Change password\" tray. You may then provide their new password, confirm it, and click the \"Change Password\" button. Backing Up and Restoring Corpus Data When logged in as user with admin privileges, you should see several buttons on the footer of the table that lists all of the corpora on the home page of your instance of Corpora. To back up or restore corpus data, click the blue \"Export/Import Corpus\" button to manage corpus backups. Backing Up Corpus data can be exported as a \"gzipped tar file,\" which includes metadata about your corpus, any files uploaded to your corpus or content types, and MongoDB database dumps of all the content in your corpus. To create an export file, select the relevant corpus from the \"Corpus\" dropdown, provide a name (a default name is optionally provided for you), and click the orange \"Create\" button. Depending on how large your corpus is, this can take some time. Once an export has been created, however, it should show up under \"Existing Exports\" beneath the creation form upon refreshing the page. Multiple exports for the same corpus may be created--they must, however, have unique names. In order to restore a corpus or migrate it to another instance of Corpora, you may download the file by clicking on its orange link in the \"Export File\" column of the Existing Exports table. It is strongly recommended that you do not rename this file after you download it. Restoring To restore a corpus export, it must be listed in the \"Existing Exports\" table. If it's not listed there, scroll to the bottom of the page where it says \"Import an Export File.\" You may simply drag and drop your downloaded export file into the gray box to make it available.* Once your export file appears in the \"Existing Exports\" table, you may click the blue \"Restore\" button to the right of it to commence the restore process. Note that the restore process maintains the original unique ID assigned to your corpus at the time of creation. As such, if you already have a version of that corpus on your instance of Corpora, you must first delete it before performing a restore. To delete an existing corpus you must be logged in as an admin user. You can then go to that corpus' home page, click on the \"Admin\" tab, scroll to the bottom, and use the corpus deletion form. Depending on the amount of data in your corpus, restoring can take a long time, as data is being restored to MongoDB, Elasticsearch, and Neo4J. * Note: Certain very large corpus export files (usually over 3GB in size) may cause the upload process to timeout, preventing you from registering it as an available corpus to restore. If this happens, you will have to register it manually. To do so, navigate to the data directory of your instance of Corpora as it exists on the machine/server hosting your instance, i.e. /corpora/data . Inside that directory will be several subdirectories such as \"archive,\" \"link,\" \"search,\" etc. Go inside the subdirectory named \"corpora\" and find the directory named exports, i.e. /corpora/data/corpora/exports . Copy your large export file into this directory. You'll then have to execute a Django management command on the machine hosting Corpora by performing the following steps: Open a terminal or command prompt. Determine the name of the container running Corpora. You can do that by running the command docker ps . This will output information about all the containers running on your machine. In the \"NAMES\" column of this output, you'll want to find the container name for Corpora, which will either be something like corpora-corpora-1 if you're using Docker Compose, or corpora_corpora.1.[alphanumeric id] if you're using Docker Swarm. Make note of this container name. Execute the following command in your terminal: docker exec -it [container name] python3 manage.py register_export_file [export filename] Note that when providing the export filename in the command above, you only need the name of the file (not the full path). Once that command executes and you get a message saying \"Export file successfully registered,\" you should be able to see it listed as an available corpus export to restore on the \"Export/Import Corpus\" page. Installing Plugins Corpora is designed with a plugin architecture that leverages Django's \"app\" convention. As such, installing plugins for Corpora is relatively easy, though you must have access to the filesystem of the server. A given plugin is ultimately a directory with a particular file structure (see creating plugins for Corpora ). To install a plugin, place its directory inside the \"plugins\" subdirectory living in the data directory for Corpora, i.e. /corpora/data/plugins . Once the plugin directory is copied there, you must also enable the plugin by adding it to the comma delimited list of enabled plugins stored in the CRP_INSTALLED_PLUGINS environment variable set for the Corpora container. The easiest way to do this is to edit the docker-compose.yml file, find the \"environment\" section of the \"corpora\" service, make sure the line specifying CRP_INSTALLED_PLUGINS isn't commented out, and add the name of the plugin directory to that variables' comma delimited value. Corpora must be restarted for it to be registered properly. And in order for containers to be aware of updated environment variables, the container must be stopped altogether and re-created by the Docker engine. To completely stop and restart Corpora while running with Docker Compose, issue these commands: # first change to your codebase directory with the docker-compose.yml file docker-compose down # wait 20 seconds or so for the containers to stop docker-compose up -d To completely stop and restart Corpora while running as a Swarm service, issue these commands: # first change to your codebase directory with the docker-compose.yml file docker stack rm corpora # wait 20 seconds or so for the containers to stop docker stack deploy corpora -c docker-compose.yml docker","title":"Managing"},{"location":"managing/#managing","text":"There are a few tasks, such as managing users, backing up and restoring corpus data, and installing plugins that Corpora admins may need to perform.","title":"Managing"},{"location":"managing/#managing-users","text":"To manage the users (or Scholars) on your instance of Corpora, click the blue \"Manage Scholars\" button in the footer of the table listing corpora on the homepage of the web application. Once on the \"Scholars\" page, you should see a table listing all the users in your instance of Corpora. You may click on the column names to sort, you can use the search box, or page through this list in order to find your user. Once you've found them, click on their username which should also be an orange link. This will bring up the \"Manage Scholar\" modal.","title":"Managing Users"},{"location":"managing/#grantingrevoking-admin-privileges","text":"Admins in Corpora are able to create a new corpus, view and edit all data for existing corpora, run all corpus notebooks, and run all tasks. You can make a user an admin for your instance of Corpora by clicking the orange \"Grant Admin Privileges\" button. Once a user is an admin, that same button will read \"Revoke Admin Privileges.\"","title":"Granting/Revoking Admin Privileges"},{"location":"managing/#grantingrevoking-corpus-permissions","text":"In order for a user to edit content, run a corpus notebook, or run certain tasks, they must either be an Admin for the instance of Corpora or be granted \"Editor\" privileges on a specific corpus. To do the latter, expand the \"Corpus permissions\" tray. In the \"New Permission\" form, provide the name of the corpus, choose \"Editor\" from the dropdown menu, and click \"Set Permission.\" To revoke that privilege, find it under \"Existing Permissions\" and choose \"None\" from the dropdown.","title":"Granting/Revoking Corpus Permissions"},{"location":"managing/#grantingrevoking-job-permissions","text":"While admins can run all jobs, users with Editor permissions on a corpus must be explicitly granted permission to run specific jobs. To do so, expand out the user's \"Job permissions\" tray. You can either check the box next to the specific task they need to be able to run, or check the \"Local (HUEY)\" box, which grants them privileges to run every local task. Once you've checked the appropriate box(es), click the orange \"Set Permissions\" button. Job permissions can be revoked by unchecking boxes and clicking \"Set Permissions\" again.","title":"Granting/Revoking Job Permissions"},{"location":"managing/#changing-passwords","text":"When logged in, individual users can change their passwords by clicking on the orange \"My Account\" button on the top right of a page in Corpora. Should they need their passwords reset, however, you may do so by pulling up their \"Manage Scholar\" modal and expanding the \"Change password\" tray. You may then provide their new password, confirm it, and click the \"Change Password\" button.","title":"Changing Passwords"},{"location":"managing/#backing-up-and-restoring-corpus-data","text":"When logged in as user with admin privileges, you should see several buttons on the footer of the table that lists all of the corpora on the home page of your instance of Corpora. To back up or restore corpus data, click the blue \"Export/Import Corpus\" button to manage corpus backups.","title":"Backing Up and Restoring Corpus Data"},{"location":"managing/#backing-up","text":"Corpus data can be exported as a \"gzipped tar file,\" which includes metadata about your corpus, any files uploaded to your corpus or content types, and MongoDB database dumps of all the content in your corpus. To create an export file, select the relevant corpus from the \"Corpus\" dropdown, provide a name (a default name is optionally provided for you), and click the orange \"Create\" button. Depending on how large your corpus is, this can take some time. Once an export has been created, however, it should show up under \"Existing Exports\" beneath the creation form upon refreshing the page. Multiple exports for the same corpus may be created--they must, however, have unique names. In order to restore a corpus or migrate it to another instance of Corpora, you may download the file by clicking on its orange link in the \"Export File\" column of the Existing Exports table. It is strongly recommended that you do not rename this file after you download it.","title":"Backing Up"},{"location":"managing/#restoring","text":"To restore a corpus export, it must be listed in the \"Existing Exports\" table. If it's not listed there, scroll to the bottom of the page where it says \"Import an Export File.\" You may simply drag and drop your downloaded export file into the gray box to make it available.* Once your export file appears in the \"Existing Exports\" table, you may click the blue \"Restore\" button to the right of it to commence the restore process. Note that the restore process maintains the original unique ID assigned to your corpus at the time of creation. As such, if you already have a version of that corpus on your instance of Corpora, you must first delete it before performing a restore. To delete an existing corpus you must be logged in as an admin user. You can then go to that corpus' home page, click on the \"Admin\" tab, scroll to the bottom, and use the corpus deletion form. Depending on the amount of data in your corpus, restoring can take a long time, as data is being restored to MongoDB, Elasticsearch, and Neo4J. * Note: Certain very large corpus export files (usually over 3GB in size) may cause the upload process to timeout, preventing you from registering it as an available corpus to restore. If this happens, you will have to register it manually. To do so, navigate to the data directory of your instance of Corpora as it exists on the machine/server hosting your instance, i.e. /corpora/data . Inside that directory will be several subdirectories such as \"archive,\" \"link,\" \"search,\" etc. Go inside the subdirectory named \"corpora\" and find the directory named exports, i.e. /corpora/data/corpora/exports . Copy your large export file into this directory. You'll then have to execute a Django management command on the machine hosting Corpora by performing the following steps: Open a terminal or command prompt. Determine the name of the container running Corpora. You can do that by running the command docker ps . This will output information about all the containers running on your machine. In the \"NAMES\" column of this output, you'll want to find the container name for Corpora, which will either be something like corpora-corpora-1 if you're using Docker Compose, or corpora_corpora.1.[alphanumeric id] if you're using Docker Swarm. Make note of this container name. Execute the following command in your terminal: docker exec -it [container name] python3 manage.py register_export_file [export filename] Note that when providing the export filename in the command above, you only need the name of the file (not the full path). Once that command executes and you get a message saying \"Export file successfully registered,\" you should be able to see it listed as an available corpus export to restore on the \"Export/Import Corpus\" page.","title":"Restoring"},{"location":"managing/#installing-plugins","text":"Corpora is designed with a plugin architecture that leverages Django's \"app\" convention. As such, installing plugins for Corpora is relatively easy, though you must have access to the filesystem of the server. A given plugin is ultimately a directory with a particular file structure (see creating plugins for Corpora ). To install a plugin, place its directory inside the \"plugins\" subdirectory living in the data directory for Corpora, i.e. /corpora/data/plugins . Once the plugin directory is copied there, you must also enable the plugin by adding it to the comma delimited list of enabled plugins stored in the CRP_INSTALLED_PLUGINS environment variable set for the Corpora container. The easiest way to do this is to edit the docker-compose.yml file, find the \"environment\" section of the \"corpora\" service, make sure the line specifying CRP_INSTALLED_PLUGINS isn't commented out, and add the name of the plugin directory to that variables' comma delimited value. Corpora must be restarted for it to be registered properly. And in order for containers to be aware of updated environment variables, the container must be stopped altogether and re-created by the Docker engine. To completely stop and restart Corpora while running with Docker Compose, issue these commands: # first change to your codebase directory with the docker-compose.yml file docker-compose down # wait 20 seconds or so for the containers to stop docker-compose up -d To completely stop and restart Corpora while running as a Swarm service, issue these commands: # first change to your codebase directory with the docker-compose.yml file docker stack rm corpora # wait 20 seconds or so for the containers to stop docker stack deploy corpora -c docker-compose.yml docker","title":"Installing Plugins"}]}